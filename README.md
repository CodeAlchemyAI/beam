# mosaicml/mpt-7b-chat

Run [mosaicml/mpt-7b-chat](https://huggingface.co/mosaicml/mpt-7b-chat) in a GPU environment with a single command. ðŸ“¡

## Speed Run

1. Signup for [Beam](http://beam.cloud)
2. Download the CLI and Python SDK
3. Clone this template locally: `beam create-app openllama`
4. Spin up a GPU environment to run inference: `beam start app.py`
5. Deploy the app as a web API: `beam deploy app.py`
